---
title: Run tests with Optic
slug: /test/with-optic
---

> When your existing tests are run through Optic, you gain the ability to fail the test suite when the API contract is not met.

import { ShowAllFrameworks } from '../../src/components/ShowAllFrameworks';
import { ShowAllTools } from '../../src/components/ShowAllTools';

**Outcome**: You can run your test with Optic

You should have tests for your API project, and [documentation](/document/baseline) you have generated with Optic.

## Collect traffic from your Automated Tests with Optic

Optic can run your tests against your project, observing the traffic and comparing it to your documentation generated with Optic. Optic will report if there are any diffs, and can fail your test suite if there are any schema changes. You don't need to add any additional tests or changes to your test process once Optic is configured correctly: all you have to do is run `api test`.

<ShowAllFrameworks/>

Capture Traffic from your other API Tools:
<ShowAllTools />

## Naming your test tasks

Optic recommends keeping things simple and calling your test task `test`, so you can run it with `api run test` or `api test`. However, if you have multiple test commands, you can call them whatever makes sense to your team. For this guide we'll stick to `api run test` to keep it simple, but you can sub this for any other task in the `optic.yml`

## Running your test tasks

Your test task is treated like a regular task, and runs with the same `api run` command you've already used to [document your api](/document/baseline). There's also an alias, `api test`, for `api run test`. 

**Run this ⤵️**

```
api run test
```

``` 
[optic] Running dependent task start...
[optic] Review the API Diff at http://localhost:34444/apis/1/diffs
[optic] Optic is observing requests made to http://localhost:3001
JSON Server is running
[optic] Running test command newman run todo-js.postman_collection.json --environment todo-js.postman_environment.json
newman

Baseline API

→ Get all Todos
  GET localhost:3001/api/todos  GET /todos 200 6.171 ms - -
[200 OK, 1.86KB, 67ms]
  ✓  Status Test

...

┌─────────────────────────┬──────────────────┬──────────────────┐
│                         │         executed │           failed │
├─────────────────────────┼──────────────────┼──────────────────┤
│              iterations │                1 │                0 │
├─────────────────────────┼──────────────────┼──────────────────┤
│                requests │                6 │                0 │
├─────────────────────────┼──────────────────┼──────────────────┤
│            test-scripts │                9 │                0 │
├─────────────────────────┼──────────────────┼──────────────────┤
│      prerequest-scripts │                6 │                0 │
├─────────────────────────┼──────────────────┼──────────────────┤
│              assertions │                2 │                0 │
├─────────────────────────┴──────────────────┴──────────────────┤
│ total run duration: 294ms                                     │
├───────────────────────────────────────────────────────────────┤
│ total data received: 1.87KB (approx)                          │
├───────────────────────────────────────────────────────────────┤
│ average response time: 21ms [min: 5ms, max: 67ms, s.d.: 21ms] │
└───────────────────────────────────────────────────────────────┘
[optic] Observed Unexpected API Behavior. Run "api status"
```

Here my test task runs `newman`, a CLI tool to run Postman collections and their included tests. In this case, our existing test collection has a few tests, but not enough to catch schema changes. Zero of the `newman` checks failed. The last line of the output shows Optic reporting "Unexpected API Behavior". `api status` will show you what has changed 

**Run this ⤵️**

```
api status
```

```
Computing API diffs... Done!
   Diffs observed for existing endpoints
     (use "api status --review" to review in the UI
         POST   /api/todos
          GET   /api/todos
        PATCH   /api/todos/{id}
✓  No undocumented URLs observed
```

In this case, there are three endpoints where we've seen differences in behavior. There aren't any undocumented URLs observed in this case. If you are expecting a change in behavior, such as adding a new endpoint or adding a field to an existing endpoint, you can run `api status --review` and [update your specification](/change). These are detected with the tests you have already written, with no changes necessary. These schema checks are kept up to date as you continue to update your specification in Optic. Lets dig in to our tests further and see what else we can learn.

### API Coverage

Optic also makes it easy to see how much of your documented API is covered by your tests. This is a helpful way to find out the coverage of your testing by how much of your API surface area is tested, not by lines of code. 70% or 80% coverage may not be helpful if your most important routes are uncovered, or if the code that's not covered is inherited on many endpoints. API coverage gives you confidence in which API endpoints are tested.

**Run this ⤵️**

```
api status --print-coverage
```

```
Computing API diffs... Done!
   Diffs observed for existing endpoints
     (use "api status --review" to review in the UI
        PATCH   /api/todos/{id}
✓  No undocumented URLs observed


 API Coverage Report:
┌──────────────────────────────────┬──────────────────────────────────────────────┬───────────────────────────────────────────────────┐
│ Endpoint                         │ Requests                                     │ Responses                                         │
├──────────────────────────────────┼──────────────────────────────────────────────┼───────────────────────────────────────────────────┤
│ /api/todos -> 100.0% covered     │ No Body: 1                                   │ 200: application/json: 1                          │
│                                  │ application/json: 1                          │ 201: application/json: 1                          │
├──────────────────────────────────┼──────────────────────────────────────────────┼───────────────────────────────────────────────────┤
│ /api/todos/{id} -> 50.0% covered │ No Body: 1                                   │ 200: application/json: 1                          │
│                                  │ application/json: No Coverage | 1 with diffs │ 200: application/json: No Coverage | 1 with diffs │
└──────────────────────────────────┴──────────────────────────────────────────────┴───────────────────────────────────────────────────┘

Based on 3 samples
┌──────────────────────────────┬──────────┬──────────┬──────────────────┐
│                              │ Observed │ Expected │ Percent Coverage │
├──────────────────────────────┼──────────┼──────────┼──────────────────┤
│ Documented Body Coverage     │ 6        │ 8        │ 75.0%            │
├──────────────────────────────┼──────────┼──────────┼──────────────────┤
│ Documented Endpoint Coverage │ 2        │ 2        │ 100.0%           │
└──────────────────────────────┴──────────┴──────────┴──────────────────┘
```

In the example above, we can see that `api status` reports a difference in behavior of one endpoint. The coverage adds a bit of context: the affected route saw a request and a body that had diffs, based on three samples. Optic expected to see 8 distinct bodies for the endpoint, but only saw 6, for 75% of coverage. Bodies are grouped by content type, and reponses are further grouped by status codes, to assure every case is covered.

Here's another example where the tests cover an undocumented endpoint.

```
Computing API diffs... Done!
   Diffs observed for existing endpoints
     (use "api status --review" to review in the UI
         POST   /api/todos
        PATCH   /api/todos/{id}
  Undocumented URLs observed
      (use "api status --review" to start documenting them
          GET   /api/todos/0fe639b6

 API Coverage Report:
┌─────────────────────────────────┬──────────────────────────────────────────────┬───────────────────────────────────────────────────┐
│ Endpoint                        │ Requests                                     │ Responses                                         │
├─────────────────────────────────┼──────────────────────────────────────────────┼───────────────────────────────────────────────────┤
│ /api/todos -> 50.0% covered     │ application/json: No Coverage | 1 with diffs │ 201: application/json: No Coverage | 1 with diffs │
│                                 │ No Body: 1                                   │ 200: application/json: 1                          │
├─────────────────────────────────┼──────────────────────────────────────────────┼───────────────────────────────────────────────────┤
│ /api/todos/{id} -> 0.0% covered │ application/json: No Coverage | 1 with diffs │ 200: application/json: No Coverage | 1 with diffs │
└─────────────────────────────────┴──────────────────────────────────────────────┴───────────────────────────────────────────────────┘

Based on 1 samples
┌──────────────────────────────┬──────────┬──────────┬──────────────────┐
│                              │ Observed │ Expected │ Percent Coverage │
├──────────────────────────────┼──────────┼──────────┼──────────────────┤
│ Documented Body Coverage     │ 2        │ 6        │ 33.3%            │
├──────────────────────────────┼──────────┼──────────┼──────────────────┤
│ Documented Endpoint Coverage │ 1        │ 2        │ 50.0%            │
└──────────────────────────────┴──────────┴──────────┴──────────────────┘
```

### How to fail your tests on a Diff

The status and coverage reports are great ways to get insight how your API's behavior has changed. You don't have to be in the loop to investigate these reports, though. Optic can be configured to exit on a diff and throw an error code, to let your command line processes know your API's schema has changed. Now your tests can fail for schema differences as well!

**Run this ⤵️**

```
api run baseline-ignores --exit-on-diff
```

```
[optic] Running dependent task start...
...
[optic] Observed Unexpected API Behavior. Review at http://localhost:34444/apis/1/diffs/local/ec7c1f5c-4de3-4efa-a95d-5cffd7462e2b
```

The output will look very similar, though Optic will exit with exit code 1. If your terminal shows the last error code or exit status, it will show you Optic exited with a failure code. You can also check the last exit code (on POSIX-style systems, `echo $?` should do the trick). If there are no diffs to report, Optic will exit with code 0.

You can also pass through your test exit codes with `--pass-exit-code`. This allows Optic to pass through a failed exit code, or exit code 1 in the event there's a diff.

### Want to run Optic in CI?

Setting up your tests to run with Optic locally gives you the ability to fail your tests when your schema is not met, without adding any additional tests. There are flags to fail tests and pass through exit codes which are particularly helpful in CI environments. Learn more about [runing in CI](/test/run-in-ci) so you can have the same benefits of schema checks with your current tests throughout your development cycle.